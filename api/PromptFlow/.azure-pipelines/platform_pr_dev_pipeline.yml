
parameters:
 - name: exec_environment
   displayName: "Execution Environment"
   default: "dev"
 - name: flow_to_execute
   displayName: "type of model to execute"

stages:
    - stage: build_validation
      displayName: build_validation
      jobs:
        - template: build_validation_pipeline.yml
          parameters:
            flow_to_execute: ${{ parameters.flow_to_execute }}

    - stage: execute_training_job
      displayName: execute_training_job
      dependsOn: 
      - build_validation
      jobs:
      - job: Execute_ml_Job_Pipeline
        steps:
        - template: templates/get_connection_details.yml

        - template: templates/configure_azureml_agent.yml
        
        #=====================================
        # Registers experiment dataset in Azure ML as Data Asset
        # Reads appropriate field values from data_config.json based on environment and data purpose
        #=====================================           
        - template: templates/execute_python_code.yml
          parameters:
            step_name: "Register Training Data"
            script_parameter: |
              python -m llmops.common.register_data_asset \
                --subscription_id "$(SUBSCRIPTION_ID)" \
                --data_purpose "pr_data" \
                --flow_to_execute ${{ parameters.flow_to_execute }} \
                --env_name ${{ parameters.exec_environment }}

        #=====================================
        # Executes Standard flow for a scenario
        # Generates Reports for each RUN as well as consolidated one
        # Execute a RUN for each unique variant combination (keeping default variant id for other nodes)
        # Loads appropriate experiment data from Azure ML data asset
        # Reads appropriate field values from mapping_config.json based on environment and evaluation flow name
        # Prompt Flow connections should pre-exist 
        # used automatic (serverless) runtime by default
        #=====================================
        - template: templates/execute_python_code.yml
          parameters:
            step_name: "Execute Standard Flow"
            script_parameter: |
              python -m llmops.common.prompt_pipeline \
                --subscription_id "$(SUBSCRIPTION_ID)" \
                --build_id $(BUILD.BUILDID) \
                --env_name ${{ parameters.exec_environment }} \
                --flow_to_execute ${{ parameters.flow_to_execute }} \
                --data_purpose "pr_data" \
                --output_file run_id.txt
