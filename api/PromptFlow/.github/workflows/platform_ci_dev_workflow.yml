name: platform_ci_dev_workflow

on:
  workflow_call:
    inputs:
      env_name:
        type: string
        description: "Execution Environment"
        required: true
        default: "dev"
      flow_type:
        type: string
        description: "The flow use-case to execute"
        required: true
        default: "web_classification"
      deployment_type:
        type: string
        description: "Determine type of deployment - aml, aks, docker, webapp"
        required: true
    secrets:
      azure_credentials:
        description: "service principal authentication to Azure"
        required: true
      connection_details:
        description: "prompt flow connection details"
        required: false
      registry_details:
        description: "prompt flow registry details"
        required: false

jobs:
  flow-experiment-and_evaluation:
    name: prompt flow experiment and evaluation job
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Actions
        uses: actions/checkout@v4

      - name: Azure login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.azure_credentials }}

      - name: Configure Azure ML Agent
        uses: ./.github/actions/configure_azureml_agent

      - name: load the current Azure subscription details
        id: subscription_details
        shell: bash
        run: |
          export subscriptionId=$(az account show --query id -o tsv)
          echo "SUBSCRIPTION_ID=$subscriptionId" >> $GITHUB_OUTPUT

      #=====================================
      # Registers experiment dataset in Azure ML as Data Asset
      # Reads appropriate field values from data_config.json based on environment and data purpose
      #=====================================      
      - name: Register experiment data asset
        uses: ./.github/actions/execute_script
        with:
          step_name: "Register experiment data asset"
          script_parameter: |
            python -m llmops.common.register_data_asset \
            --subscription_id ${{ steps.subscription_details.outputs.SUBSCRIPTION_ID }} \
            --data_purpose "training_data" \
            --flow_to_execute ${{ inputs.flow_type }} \
            --env_name ${{ inputs.env_name }}

      #=====================================
      # Executes Standard flow for a scenario
      # Generates Reports for each RUN as well as consolidated one
      # Execute a RUN for each unique variant combination (keeping default variant id for other nodes)
      # Loads appropriate experiment data from Azure ML data asset
      # Reads appropriate field values from mapping_config.json based on environment and evaluation flow name
      # Prompt Flow connections should pre-exist 
      # used automatic (serverless) runtime by default
      # writes the RUN ID in run_id.txt file. Used in next step
      #=====================================
      - name: Execute prompt flow bulk run
        uses: ./.github/actions/execute_script
        with:
          step_name: "Execute prompt flow bulk run"
          script_parameter: |
            python -m llmops.common.prompt_pipeline \
            --subscription_id ${{ steps.subscription_details.outputs.SUBSCRIPTION_ID }} \
            --build_id ${{ github.run_id }} \
            --flow_to_execute ${{ inputs.flow_type }} \
            --env_name ${{ inputs.env_name }} \
            --data_purpose "training_data" \
            --output_file run_id.txt

      #=====================================
      # Reads run_id.txt file. Assigns it to variable RUN_NAME
      # RUN_NAME Used in next step for evaluation of flows
      #=====================================   
      - name: Read PromptFlow Runs
        shell: bash
        run: |
          readarray arr <"run_id.txt"
          run_name=${arr[0]}
          echo $run_name
          echo "RUN_NAME=${run_name}"  >> "$GITHUB_ENV"
          echo $PWD

      #=====================================
      # Registers evaluation dataset in Azure ML as Data Asset
      # Reads appropriate field values from data_config.json based on environment and data purpose
      #=====================================
      - name: Register evaluation data asset
        uses: ./.github/actions/execute_script
        with:
          step_name: "Register evaluation data asset"
          script_parameter: |
            python -m llmops.common.register_data_asset \
            --subscription_id ${{ steps.subscription_details.outputs.SUBSCRIPTION_ID }} \
            --data_purpose "test_data" \
            --flow_to_execute ${{ inputs.flow_type }} \
            --env_name ${{ inputs.env_name }}

      #=====================================
      # Executes all Evaluation flows available for a scenario
      # Generates Reports for each RUN as well as consolidated one
      # Uses each RUN ID as input to run evaluation against
      # Loads appropriate evaluation data from Azure ML data asset
      # Reads appropriate field values from mapping_config.json based on environment and evaluation flow name
      # Prompt Flow connections should pre-exist 
      # used automatic (serverless) runtime by default
      #=====================================
      - name: Execute bulk run evaluations
        uses: ./.github/actions/execute_script
        with:
          step_name: "Execute bulk run evaluations"
          script_parameter: |
            python -m llmops.common.prompt_eval \
            --subscription_id ${{ steps.subscription_details.outputs.SUBSCRIPTION_ID }} \
            --build_id ${{ github.run_id }} \
            --flow_to_execute ${{ inputs.flow_type }} \
            --env_name ${{ inputs.env_name }} \
            --data_purpose "test_data" \
            --run_id "$RUN_NAME"

      #=====================================
      # Published generated reports in csv and html format
      # Available as pipeline artifacts
      #=====================================
      - name: Archive CSV
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-reports
          path: ./reports

  #=====================================
  # Execute platform_cd_dev_workflow flow for deployment of flows
  #=====================================
  deploy-flow:
    uses: ./.github/workflows/platform_cd_dev_workflow.yml
    needs: flow-experiment-and_evaluation
    with:
      env_name: ${{ inputs.env_name }}
      flow_type: ${{ inputs.flow_type }} 
      deployment_type: ${{ inputs.deployment_type }}
    secrets:
      azure_credentials: ${{ secrets.azure_credentials }}  
      connection_details: ${{ secrets.connection_details }}
      registry_details: ${{ secrets.registry_details }}
